{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17748a3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-04T22:14:12.004393Z",
     "iopub.status.busy": "2025-09-04T22:14:12.003977Z",
     "iopub.status.idle": "2025-09-04T22:14:14.224251Z",
     "shell.execute_reply": "2025-09-04T22:14:14.223072Z"
    },
    "papermill": {
     "duration": 2.226332,
     "end_time": "2025-09-04T22:14:14.226395",
     "exception": false,
     "start_time": "2025-09-04T22:14:12.000063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfdcc4dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T22:14:14.232223Z",
     "iopub.status.busy": "2025-09-04T22:14:14.231746Z",
     "iopub.status.idle": "2025-09-04T22:14:20.328377Z",
     "shell.execute_reply": "2025-09-04T22:14:20.326766Z"
    },
    "papermill": {
     "duration": 6.101755,
     "end_time": "2025-09-04T22:14:20.330497",
     "exception": false,
     "start_time": "2025-09-04T22:14:14.228742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Digit Recognizer - Kaggle\n",
    "# Baseline ML + CNN + Optuna\n",
    "# =========================\n",
    "\n",
    "# Install needed packages (if using Colab, Kaggle already has them)\n",
    "!pip install optuna lightgbm xgboost -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5e5b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T22:14:20.338602Z",
     "iopub.status.busy": "2025-09-04T22:14:20.337307Z",
     "iopub.status.idle": "2025-09-05T07:12:07.839691Z",
     "shell.execute_reply": "2025-09-05T07:12:07.838296Z"
    },
    "papermill": {
     "duration": 32267.509422,
     "end_time": "2025-09-05T07:12:07.842298",
     "exception": false,
     "start_time": "2025-09-04T22:14:20.332876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 22:14:25.860217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757024066.123371      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757024066.203538      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Baseline ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9128571428571428\n",
      "=== Random Forest ===\n",
      "Validation Accuracy: 0.965\n",
      "=== XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 22:32:56,041] A new study created in memory with name: no-name-c9fb82e8-59f4-4e4d-a98f-8150dddf0ca6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9766666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/657962977.py:110: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-09-04 22:32:56.056813: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "[I 2025-09-04 22:54:16,958] Trial 0 finished with value: 0.9952380657196045 and parameters: {'dropout1': 0.22335580816706768, 'dropout2': 0.5720402733115313, 'dense_units': 512, 'lr': 0.003605100072593643, 'batch_size': 64}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-04 23:17:02,891] Trial 1 finished with value: 0.9952380657196045 and parameters: {'dropout1': 0.2913542678131094, 'dropout2': 0.44715108689524546, 'dense_units': 128, 'lr': 0.000984879651317627, 'batch_size': 32}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-04 23:39:01,045] Trial 2 finished with value: 0.9938095211982727 and parameters: {'dropout1': 0.23051890859193816, 'dropout2': 0.46253183455884994, 'dense_units': 512, 'lr': 0.00010444180183010965, 'batch_size': 64}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 00:00:50,128] Trial 3 finished with value: 0.9942857027053833 and parameters: {'dropout1': 0.26547852805192884, 'dropout2': 0.4632789985263529, 'dense_units': 512, 'lr': 0.00022368033855651613, 'batch_size': 64}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 00:20:51,210] Trial 4 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.26036274819758676, 'dropout2': 0.39062422111214345, 'dense_units': 128, 'lr': 0.003457269724242574, 'batch_size': 128}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 00:42:49,665] Trial 5 finished with value: 0.9942857027053833 and parameters: {'dropout1': 0.27206289972995085, 'dropout2': 0.3859969475619349, 'dense_units': 256, 'lr': 0.0002676597348640019, 'batch_size': 128}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 01:03:55,923] Trial 6 finished with value: 0.9930952191352844 and parameters: {'dropout1': 0.32547522597112755, 'dropout2': 0.5481543715239747, 'dense_units': 256, 'lr': 0.00011407954358994333, 'batch_size': 128}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 01:29:18,080] Trial 7 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.2763864372479927, 'dropout2': 0.49551127582419485, 'dense_units': 128, 'lr': 0.0019823753157732662, 'batch_size': 32}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 01:50:16,023] Trial 8 finished with value: 0.9926190376281738 and parameters: {'dropout1': 0.38053684266973975, 'dropout2': 0.48583570785763963, 'dense_units': 256, 'lr': 0.00019619387122640525, 'batch_size': 128}. Best is trial 0 with value: 0.9952380657196045.\n",
      "[I 2025-09-05 02:14:45,430] Trial 9 finished with value: 0.996666669845581 and parameters: {'dropout1': 0.3348594091594718, 'dropout2': 0.47728390110604013, 'dense_units': 512, 'lr': 0.0013562036996338472, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 02:39:24,805] Trial 10 finished with value: 0.994523823261261 and parameters: {'dropout1': 0.3468369312264124, 'dropout2': 0.30482452554629635, 'dense_units': 512, 'lr': 0.009621486532111543, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 03:04:27,934] Trial 11 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.22302150850985825, 'dropout2': 0.578018154030636, 'dense_units': 512, 'lr': 0.0008686015834954192, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 03:26:44,498] Trial 12 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.3290804142431325, 'dropout2': 0.5989434182282728, 'dense_units': 512, 'lr': 0.002748116043975353, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 03:51:06,385] Trial 13 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.2030244911070812, 'dropout2': 0.5276928258981713, 'dense_units': 512, 'lr': 0.00618935936761245, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 04:15:47,870] Trial 14 finished with value: 0.9947618842124939 and parameters: {'dropout1': 0.3732502374567217, 'dropout2': 0.4130868437118436, 'dense_units': 512, 'lr': 0.0005156055483901301, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 04:36:48,421] Trial 15 finished with value: 0.9952380657196045 and parameters: {'dropout1': 0.3118156620702137, 'dropout2': 0.5342316833543844, 'dense_units': 512, 'lr': 0.001729425947644947, 'batch_size': 64}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 05:06:12,916] Trial 16 finished with value: 0.9954761862754822 and parameters: {'dropout1': 0.34985315273144313, 'dropout2': 0.32162482211243737, 'dense_units': 512, 'lr': 0.004726447126606888, 'batch_size': 32}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 05:31:53,345] Trial 17 finished with value: 0.9952380657196045 and parameters: {'dropout1': 0.356523323640279, 'dropout2': 0.31571697029183204, 'dense_units': 512, 'lr': 0.000552829452847612, 'batch_size': 32}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 06:01:44,291] Trial 18 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.39502427629675063, 'dropout2': 0.3431737079314964, 'dense_units': 128, 'lr': 0.00651081312754118, 'batch_size': 32}. Best is trial 9 with value: 0.996666669845581.\n",
      "[I 2025-09-05 06:31:37,004] Trial 19 finished with value: 0.9950000047683716 and parameters: {'dropout1': 0.34917678694759446, 'dropout2': 0.4283703503852285, 'dense_units': 256, 'lr': 0.0014723100321961185, 'batch_size': 32}. Best is trial 9 with value: 0.996666669845581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'dropout1': 0.3348594091594718, 'dropout2': 0.47728390110604013, 'dense_units': 512, 'lr': 0.0013562036996338472, 'batch_size': 64}\n",
      "Epoch 1/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 127ms/step - accuracy: 0.7712 - loss: 0.7907 - val_accuracy: 0.9852 - val_loss: 0.0508 - learning_rate: 0.0014\n",
      "Epoch 2/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 127ms/step - accuracy: 0.9558 - loss: 0.1400 - val_accuracy: 0.9874 - val_loss: 0.0375 - learning_rate: 0.0014\n",
      "Epoch 3/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 131ms/step - accuracy: 0.9673 - loss: 0.1085 - val_accuracy: 0.9921 - val_loss: 0.0234 - learning_rate: 0.0014\n",
      "Epoch 4/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 134ms/step - accuracy: 0.9705 - loss: 0.0947 - val_accuracy: 0.9914 - val_loss: 0.0242 - learning_rate: 0.0014\n",
      "Epoch 5/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 139ms/step - accuracy: 0.9749 - loss: 0.0837 - val_accuracy: 0.9929 - val_loss: 0.0268 - learning_rate: 0.0014\n",
      "Epoch 6/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 137ms/step - accuracy: 0.9783 - loss: 0.0710 - val_accuracy: 0.9905 - val_loss: 0.0292 - learning_rate: 0.0014\n",
      "Epoch 7/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.9824 - loss: 0.0598 - val_accuracy: 0.9931 - val_loss: 0.0201 - learning_rate: 6.7810e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 140ms/step - accuracy: 0.9823 - loss: 0.0548 - val_accuracy: 0.9948 - val_loss: 0.0183 - learning_rate: 6.7810e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 134ms/step - accuracy: 0.9862 - loss: 0.0454 - val_accuracy: 0.9943 - val_loss: 0.0184 - learning_rate: 6.7810e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 133ms/step - accuracy: 0.9864 - loss: 0.0445 - val_accuracy: 0.9931 - val_loss: 0.0235 - learning_rate: 6.7810e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 130ms/step - accuracy: 0.9861 - loss: 0.0450 - val_accuracy: 0.9929 - val_loss: 0.0218 - learning_rate: 6.7810e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 130ms/step - accuracy: 0.9880 - loss: 0.0378 - val_accuracy: 0.9940 - val_loss: 0.0184 - learning_rate: 3.3905e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 129ms/step - accuracy: 0.9878 - loss: 0.0379 - val_accuracy: 0.9933 - val_loss: 0.0195 - learning_rate: 3.3905e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 130ms/step - accuracy: 0.9883 - loss: 0.0353 - val_accuracy: 0.9948 - val_loss: 0.0173 - learning_rate: 3.3905e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 130ms/step - accuracy: 0.9884 - loss: 0.0358 - val_accuracy: 0.9955 - val_loss: 0.0165 - learning_rate: 3.3905e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 132ms/step - accuracy: 0.9905 - loss: 0.0314 - val_accuracy: 0.9945 - val_loss: 0.0152 - learning_rate: 3.3905e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 128ms/step - accuracy: 0.9889 - loss: 0.0327 - val_accuracy: 0.9940 - val_loss: 0.0177 - learning_rate: 3.3905e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 130ms/step - accuracy: 0.9904 - loss: 0.0310 - val_accuracy: 0.9943 - val_loss: 0.0185 - learning_rate: 3.3905e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 129ms/step - accuracy: 0.9901 - loss: 0.0315 - val_accuracy: 0.9943 - val_loss: 0.0169 - learning_rate: 3.3905e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 129ms/step - accuracy: 0.9912 - loss: 0.0284 - val_accuracy: 0.9955 - val_loss: 0.0165 - learning_rate: 1.6953e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 129ms/step - accuracy: 0.9914 - loss: 0.0275 - val_accuracy: 0.9952 - val_loss: 0.0150 - learning_rate: 1.6953e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 131ms/step - accuracy: 0.9923 - loss: 0.0233 - val_accuracy: 0.9945 - val_loss: 0.0167 - learning_rate: 1.6953e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 132ms/step - accuracy: 0.9914 - loss: 0.0272 - val_accuracy: 0.9950 - val_loss: 0.0155 - learning_rate: 1.6953e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 119ms/step - accuracy: 0.9919 - loss: 0.0256 - val_accuracy: 0.9960 - val_loss: 0.0142 - learning_rate: 1.6953e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 121ms/step - accuracy: 0.9937 - loss: 0.0217 - val_accuracy: 0.9948 - val_loss: 0.0166 - learning_rate: 1.6953e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 131ms/step - accuracy: 0.9924 - loss: 0.0256 - val_accuracy: 0.9945 - val_loss: 0.0163 - learning_rate: 1.6953e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 138ms/step - accuracy: 0.9921 - loss: 0.0249 - val_accuracy: 0.9948 - val_loss: 0.0154 - learning_rate: 1.6953e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 135ms/step - accuracy: 0.9928 - loss: 0.0226 - val_accuracy: 0.9948 - val_loss: 0.0149 - learning_rate: 8.4763e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 125ms/step - accuracy: 0.9928 - loss: 0.0216 - val_accuracy: 0.9952 - val_loss: 0.0147 - learning_rate: 8.4763e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 129ms/step - accuracy: 0.9944 - loss: 0.0201 - val_accuracy: 0.9955 - val_loss: 0.0149 - learning_rate: 8.4763e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 125ms/step - accuracy: 0.9928 - loss: 0.0217 - val_accuracy: 0.9955 - val_loss: 0.0147 - learning_rate: 4.2381e-05\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step\n",
      "✅ Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Imports\n",
    "# -------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Flatten, Conv2D, MaxPooling2D,\n",
    "                                     BatchNormalization)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import optuna\n",
    "\n",
    "# -------------------------\n",
    "# Load Data\n",
    "# -------------------------\n",
    "train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n",
    "\n",
    "X = train.drop(\"label\", axis=1).values\n",
    "y = train[\"label\"].values\n",
    "\n",
    "# Normalize\n",
    "X = X / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Baseline ML Models\n",
    "# -------------------------\n",
    "print(\"=== Logistic Regression Baseline ===\")\n",
    "log_reg = LogisticRegression(max_iter=200, solver=\"saga\", n_jobs=-1)\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Validation Accuracy:\", log_reg.score(X_val, y_val))\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "rf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Validation Accuracy:\", rf.score(X_val, y_val))\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "xg = xgb.XGBClassifier(tree_method=\"hist\", n_estimators=500, max_depth=8)\n",
    "xg.fit(X_train, y_train)\n",
    "print(\"Validation Accuracy:\", xg.score(X_val, y_val))\n",
    "\n",
    "# -------------------------\n",
    "# Deep Learning (CNN)\n",
    "# -------------------------\n",
    "X_train_cnn = X_train.reshape(-1,28,28,1)\n",
    "X_val_cnn = X_val.reshape(-1,28,28,1)\n",
    "test_cnn = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "datagen.fit(X_train_cnn)\n",
    "\n",
    "def build_cnn(dropout1=0.25, dropout2=0.5, dense_units=256, lr=1e-3):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(dropout1),\n",
    "\n",
    "        Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(dropout1),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout2),\n",
    "        Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with Optuna\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0.2, 0.4)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0.3, 0.6)\n",
    "    dense_units = trial.suggest_categorical(\"dense_units\", [128, 256, 512])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "\n",
    "    model = build_cnn(dropout1, dropout2, dense_units, lr)\n",
    "\n",
    "    es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    rlrop = ReduceLROnPlateau(patience=3, factor=0.5, verbose=0)\n",
    "\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train_cnn, y_train, batch_size=batch_size),\n",
    "        validation_data=(X_val_cnn, y_val),\n",
    "        epochs=20,\n",
    "        callbacks=[es, rlrop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    return val_acc\n",
    "\n",
    "# ⚡ Run only ~20 trials (increase if GPU/time allows)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# -------------------------\n",
    "# Train Final CNN with Best Params\n",
    "# -------------------------\n",
    "best = study.best_params\n",
    "final_model = build_cnn(best[\"dropout1\"], best[\"dropout2\"], best[\"dense_units\"], best[\"lr\"])\n",
    "\n",
    "es = EarlyStopping(patience=7, restore_best_weights=True)\n",
    "rlrop = ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "\n",
    "final_model.fit(\n",
    "    datagen.flow(X_train_cnn, y_train, batch_size=best[\"batch_size\"]),\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    epochs=40,\n",
    "    callbacks=[es, rlrop, checkpoint]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Make Submission\n",
    "# -------------------------\n",
    "predictions = np.argmax(final_model.predict(test_cnn), axis=1)\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": np.arange(1, len(predictions)+1),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Submission file saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32287.588772,
   "end_time": "2025-09-05T07:12:12.714233",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T22:14:05.125461",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
